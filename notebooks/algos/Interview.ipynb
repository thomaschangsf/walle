{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe332b5-b8b8-4ad3-b4b0-2ee7b4fe5175",
   "metadata": {},
   "source": [
    "# 1 Learnings\n",
    "- Walk through ALL the examples fefore designing the alogorithms\n",
    "- Use more descriptive variable, helpful toward end of problem and things get blurred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b9557-4540-40ce-85b1-47879a0533ee",
   "metadata": {},
   "source": [
    "### Algorithm Families\n",
    "- Sub Linear\n",
    "    * Constant\n",
    "    * O(1)\n",
    "- Polynomial\n",
    "    * Linear: O(N)\n",
    "    * O(N Log N)\n",
    "    * O($N^2$)\n",
    "- Exponential\n",
    "    * recursive algorithm ==can== be exponential\n",
    "    * O($N^3$)\n",
    "    * Exponential: O($2^n$)\n",
    "        - Recursive algo solves a problem of size N by solving ==two== smaller problem of size N-1. Without maintaing state, we could end up with duplicate work.\n",
    "        - Ex: Tower of Hanoi:\n",
    "    * Factorial: O(N!)\n",
    "        - Generate all permutation of a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d502b6-70c0-49c4-ba23-6c228f72531f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4b22f2b-7fb0-457e-bcab-8ee80056a875",
   "metadata": {},
   "source": [
    "# 2 Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ab47d-fb3b-42ec-b525-4270051f2dbd",
   "metadata": {},
   "source": [
    "### Hangman (MoveWorks)\n",
    "- Write a function to predict the next probable word, give:\n",
    "    * mystery_word: d _ _ \n",
    "    * previous_guesses: ['d']\n",
    "    * word_pool: [\"dry\", \"don\", \"apple\", \"dog\", \"dri\"]\n",
    "- Output: o because o is alpha numerically smaller than r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f31e72-4f34-4c6f-9331-efcb8607d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Edge cases missed: mystery_word has to be same len as word_pool\n",
    "def predict_next_char(mystery_word, prev_guesses, word_pool):\n",
    "    # --------------------------------------\n",
    "    # Build stats\n",
    "    # --------------------------------------\n",
    "    probability_map = Counter()\n",
    "    for w in word_pool:\n",
    "        #probability_map.update(list(w)) # w.split(\" \") does not work\n",
    "        probability_map.update([c for c in w])\n",
    "        \n",
    "    # --------------------------------------\n",
    "    # Filter: Create word_candidates\n",
    "    # --------------------------------------\n",
    "    index_to_alphabets = [ (i, c) for i, c in enumerate(mystery_word) if c.isalpha() ]\n",
    "    word_candidates = []\n",
    "    for w in word_pool:\n",
    "        if len(w) != len(mystery_word):\n",
    "            continue\n",
    "        if all(w[i] == c for i, c in index_to_alphabets):\n",
    "            word_candidates.append(w)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Rank\n",
    "    # --------------------------------------\n",
    "    demand_prediction = []\n",
    "    for i in range(len(mystery_word)):\n",
    "        if mystery_word[i].isalpha():\n",
    "            continue\n",
    "        for w in word_candidates:\n",
    "            demand_prediction.append( (probability_map[w[i]], w[i]) )\n",
    "    \n",
    "    demand_prediction.sort(key=lambda t: (-t[0], t[1]) )\n",
    "    \n",
    "    return score_prediction[0][1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f4cd76-6d6e-4105-9ae3-6ede73b2ce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 4, 'p': 2, 'n': 2, 'l': 1, 'e': 1, 'b': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w1 = \"apple\"\n",
    "w2 = \"banana\"\n",
    "c = Counter([c for c in w1])\n",
    "\n",
    "c.update([c for c in w2])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05dc9f-b643-472a-97a3-dd32700a9e29",
   "metadata": {},
   "source": [
    "### Average of window_size [Facebook]\n",
    "- Given an array arr, return an result where the value is the average of the preceding window size\n",
    "- Example:\n",
    "    * Inputs: window_size =3, arr=[1, 2, 3, 4, 5]\n",
    "    * Output: result = [6/3=2, 9/3=3, 12/3=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c97af5-6656-484f-95e0-1edb92650f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3.0, 4.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learning: prefix_sum[i[ is the sum \"INCLUDEING\" arr[i]\n",
    "def find_avg_of_window(arr= [1, 2, 3, 4, 5], window_size=3):\n",
    "    if len(arr) < window_size:\n",
    "        return []\n",
    "    \n",
    "    prefix_sums = [arr[0]]\n",
    "    # prefix_sum = [1, 3, 6, 10, 15]\n",
    "    for i in range(1, len(arr)):\n",
    "        prefix_sums.append(prefix_sums[i-1] + arr[i])\n",
    "\n",
    "    result = [prefix_sums[window_size-1]]\n",
    "    for j in range(window_size, len(arr)):\n",
    "        result.append( (prefix_sums[j] - prefix_sums[j-window_size])/window_size )\n",
    "    \n",
    "    return result\n",
    "\n",
    "find_avg_of_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f480c48b-df78-4266-928f-8ab62ef1db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LCA\n",
    "#       3\n",
    "#      /  \\\n",
    "#     9    7\n",
    "#   / \\     \\\n",
    "#  2   6     4\n",
    "#\n",
    "# TC1: 2, 6 --> 9\n",
    "# TC2: 7, 6 --> 3\n",
    "# TC3: 7, 4 --> 7\n",
    "\n",
    "def lca(root, left_node, right_node):\n",
    "    # dfs returns null or a node in (lca, left_node, right_node) \n",
    "    def dfs(curr_node):\n",
    "        # Base condition\n",
    "        if not curr_node or (curr_node == left_node) or (curr_node == right_node):\n",
    "            return curr_node\n",
    "\n",
    "        left = dfs( curr_node.left )\n",
    "        right = dfs( curr_node.right )\n",
    "        if left and right:\n",
    "            return curr_node\n",
    "        else:\n",
    "            return left or right\n",
    "    \n",
    "    return dfs(root)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328b607-ee3f-401d-94e7-605751957ad1",
   "metadata": {},
   "source": [
    "### Raspbery AI\n",
    "- Given a corpus of sentences and char_count, return  sentence(s) following a specific heuristc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16bf9cb5-f322-42fd-a120-46da894c81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def recommend(sentences, char_cnt):\n",
    "    # Step 1: Estimate the unigram distribution from the input documents\n",
    "    word_counts = Counter()\n",
    "    for s in sentences:\n",
    "        word_counts.update(s.split(\" \"))\n",
    "    N = sum(word_counts.values())\n",
    "    p = { w: cnt/N for w, cnt in word_counts.items() }\n",
    "\n",
    "    # runtime: n(log n) if requires sort (ie largeer n) or O(n) for small  \n",
    "    best_word = word_counts.most_common(1)[0][0] # most_common return a list of tuples (word, cnt) in descemdomg prder\n",
    "\n",
    "    summary = \"\"\n",
    "    while char_cnt > 0:\n",
    "        # Step 2: For each sentence s_j, assign a weight equal to the average probability of the words it contain\n",
    "        avgscore_to_sentence = []\n",
    "        for s in sentences:\n",
    "            scores = [ p[word] for word in s.split(\" \") if word in p ]\n",
    "            avgscore_to_sentence.append( ( sum(scores) / len(scores), s) )\n",
    "\n",
    "        # Step 3: Pick the highest scoring sentence that also contains the best scoring word and add it to the summary (so long as it fits within the length limit)\n",
    "        avgscore_to_sentence_filtered = [ (score, s) for score, s in avgscore_to_sentence if best_word in s]\n",
    "        avgscore_to_sentence_filtered.sort(key=lambda t: t[0])\n",
    "        best_sentence = avgscore_to_sentence_filtered[-1][1]\n",
    "\n",
    "        # Step 4: For each word in teh sentence selected in step 3, update its probability\n",
    "        for w in best_sentence.split(\" \"):\n",
    "            p[word] = p[word] * p[word]\n",
    "\n",
    "        # Step 5: If the desired summary length has not been reached, go to step 2\n",
    "        if char_cnt < len(best_sentence):\n",
    "            return summary\n",
    "        else:\n",
    "            char_cnt -= len(best_sentence)\n",
    "            summary += best_sentence\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb5a3f32-06ac-4146-b1a0-7d2b56a01073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"apple\" in \"apple pie\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71172e4a-7408-4811-a014-6c197e5266a9",
   "metadata": {},
   "source": [
    "### Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45c5de3-a340-4c51-91b7-73866a1f05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# They have the same length (i.e., the same number of words)\n",
    "# sentence1[i] and sentence2[i] are similar.\n",
    "# Notice that a word is always similar to itself, also notice that the similarity relation is transitive. For example, if the words a and b are similar, and the words b and c are similar, then a and c are similar.\n",
    "\n",
    "# #Example 1:\n",
    "\n",
    "# #Input: sentence1 = [\"great\",\"acting\",\"skills\"], sentence2 = [\"fine\",\"drama\",\"talent\"], similarPairs = [[\"great\",\"good\"],[\"fine\",\"good\"],[\"drama\",\"acting\"],[\"skills\",\"talent\"]]\n",
    "# #Output: true\n",
    "# #Explanation: The two sentences have the same length and each word i of sentence1 is also similar to the corresponding word in sentence2.\n",
    "# #Example 2:\n",
    "\n",
    "# #Input: sentence1 = [\"I\",\"love\",\"shows\"], sentence2 = [\"I\",\"love\",\"onepiece\"], similarPairs = [[\"manga\",\"onepiece\"],[\"platform\",\"anime\"],[\"shows\",\"platform\"],[\"anime\",\"manga\"]]\n",
    "# #Output: true\n",
    "# #Explanation: \"shows\" --> \"platform\" --> \"anime\" --> \"manga\" --> \"onepiece\".\n",
    "# #Since \"shows is similar to \"onepiece\" and the first two words are the same, the two sentences are similar.\n",
    "# #Example 3:\n",
    "\n",
    "# #Input: sentence1 = [\"I\",\"love\",\"shows\"], sentence2 = [\"I\",\"love\",\"onepiece\"], similarPairs = [[\"manga\",\"hunterXhunter\"],[\"platform\",\"anime\"],[\"shows\",\"platform\"],[\"anime\",\"manga\"]]\n",
    "# #Output: false\n",
    "# #Explanation: \"shows\" is not similar to \"onepiece\".\n",
    "\n",
    "# # Req: Similar AND COND\n",
    "# #1. len(s1) == len(s2) ; \n",
    "# #2. s1[x] == s2[y]  or  rel(x) --> rel(y)\n",
    "\n",
    "# # Assumptions\n",
    "# #- if not same length --> false\n",
    "# #- [],[] --> true\n",
    "# #- any numerics\n",
    "\n",
    "# # rel(x) --> rel(y)\n",
    "# #1. map of continual lookup\n",
    "# #   DFS vs BFS(*)\n",
    "# #2. { word : [associated, x, y]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412740fd-9202-4879-8397-b8600b2f876f",
   "metadata": {},
   "source": [
    "##### V1: Using BFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c5a57-3f24-42bc-ae04-120d4d2d9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def is_similar(sentence1, sentence2, similarPairs):\n",
    "    n, m = len(sentence1), len(sentence2)\n",
    "    if n != m:\n",
    "        return False\n",
    "\n",
    "    lookup = defaultdict(list)\n",
    "    for items in similarPairs:\n",
    "        # Bidirectional\n",
    "        lookup[items[0]].append(items[1])\n",
    "        lookup[items[1]].append(items[0])\n",
    "\n",
    "    for w1, w2 in zip(sentence1, sentence2):\n",
    "        if (w1 != w2) and not traverse(w1, w2, lookup):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# # V = # corpus\n",
    "# #similarPairs = [[\"manga\",\"onepiece\"],[\"platform\",\"anime\"],[\"shows\",\"platform\"],[\"anime\",\"manga\"]]\n",
    "# # graph: matrix --> space V^2\n",
    "# # BFS: queue , more efficientt space\n",
    "# # Explanation: \n",
    "# #  \"w1=shows\" --> \"platform\" --> \"anime\" --> \"manga\" --> \"onepiece\".\n",
    "# #  \"w1=shows\" --> \"watch\" --> \n",
    "# # queue: FIFO\n",
    "from collections import deque\n",
    "# Implement transitive property with BFS\n",
    "def traverse(source, target, lookup):\n",
    "    queue = deque([source]) # Miss here\n",
    "    visited = set()\n",
    "\n",
    "    while queue:\n",
    "        curr_word = queue.popleft()\n",
    "    \n",
    "        for related_word in lookup[curr_word]:\n",
    "            if related_word == target:\n",
    "                return True\n",
    "\n",
    "            # Missed this            \n",
    "            if related_word not in visited:\n",
    "                queue.append(related_word)\n",
    "                visited.add(related_word)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d3202-a30f-4222-b8a0-970af1ec91e0",
   "metadata": {},
   "source": [
    "##### V2: Build a Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82207c38-388d-4471-8db1-cf74861b6c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'great': ['good'],\n",
       "             'good': ['great', 'fine'],\n",
       "             'fine': ['good'],\n",
       "             'drama': ['acting'],\n",
       "             'acting': ['drama'],\n",
       "             'skills': ['talent'],\n",
       "             'talent': ['skills']})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# NOT RIGHT\n",
    "def build_lookup_fails(similar_pairs):\n",
    "    similar_dict = { pair[0]: pair[1] for pair in similar_pairs }\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    lookup = defaultdict(list)\n",
    "    for k, v in similar_dict.items():\n",
    "        curr_key = k\n",
    "        while curr_key in similar_dict:\n",
    "            v = similar_dict[curr_key]\n",
    "            lookup[k].append( v )\n",
    "            lookup[v].append( k)\n",
    "            curr_key = v\n",
    "    return lookup\n",
    "    \n",
    "#similar_pairs = [[\"manga\",\"onepiece\"],[\"platform\",\"anime\"],[\"shows\",\"platform\"],[\"anime\",\"manga\"]]\n",
    "similar_pairs = [[\"great\",\"good\"],[\"fine\",\"good\"],[\"drama\",\"acting\"], [\"skills\",\"talent\"]]\n",
    "lookup = build_lookup(similar_pairs)\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d32b8854-ee17-4a29-9a81-928ac2e09830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'great': ['good', 'fine'],\n",
       "             'good': ['great', 'fine'],\n",
       "             'fine': ['great', 'good'],\n",
       "             'drama': ['acting'],\n",
       "             'acting': ['drama'],\n",
       "             'skills': ['talent'],\n",
       "             'talent': ['skills']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "def build_lookup_success(similar_pairs):\n",
    "    # Build adjacency list (graph)\n",
    "    graph = defaultdict(set)\n",
    "    for word1, word2 in similar_pairs:\n",
    "        graph[word1].add(word2)\n",
    "        graph[word2].add(word1)\n",
    "    \n",
    "    # Function to find all connected words via BFS\n",
    "    def get_connected_words(start, graph, visited):\n",
    "        queue = deque([start])\n",
    "        cluster = []\n",
    "        while queue:\n",
    "            word = queue.popleft()\n",
    "            if word in visited:\n",
    "                continue\n",
    "            visited.add(word)\n",
    "            cluster.append(word)\n",
    "            queue.extend(graph[word])\n",
    "        return cluster\n",
    "    \n",
    "    # Create the similarity dictionary\n",
    "    similar_dict = defaultdict(list)\n",
    "    visited = set()\n",
    "    \n",
    "    for word in graph:\n",
    "        if word not in visited:\n",
    "            connected_words = get_connected_words(word, graph, visited)\n",
    "            for w in connected_words:\n",
    "                similar_dict[w] = [x for x in connected_words if x != w]\n",
    "\n",
    "    return similar_dict\n",
    "\n",
    "similar_pairs = [[\"great\",\"good\"],[\"fine\",\"good\"],[\"drama\",\"acting\"], [\"skills\",\"talent\"]]\n",
    "lookup = build_lookup_success(similar_pairs)\n",
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb1e68b5-102e-4c21-a432-7ca83ae6bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar_v2(sentence1, sentence2, similar_pairs):\n",
    "    m, n = len(sentence1), len(sentence2)\n",
    "    if m != n:\n",
    "        return False\n",
    "\n",
    "    lookup = build_lookup(similar_pairs)\n",
    "    print(f'lookup={lookup}\\n')\n",
    "    \n",
    "    for w1, w2 in zip(sentence1, sentence2):\n",
    "        print(w1, w2)\n",
    "        if (w1 != w2):\n",
    "            similar_words = lookup.get(w1)\n",
    "            print(f'\\tsimlar_words = {similar_words}')\n",
    "            if (similar_words == None) or (w2 not in similar_words):\n",
    "                return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2d30cb8-4bba-4039-a0d7-861ac3e37cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup=defaultdict(<class 'list'>, {'great': ['good', 'fine'], 'good': ['great', 'fine'], 'fine': ['great', 'good'], 'drama': ['acting'], 'acting': ['drama'], 'skills': ['talent'], 'talent': ['skills']})\n",
      "\n",
      "great fine\n",
      "\tsimlar_words = ['good', 'fine']\n",
      "acting drama\n",
      "\tsimlar_words = ['drama']\n",
      "skills talent\n",
      "\tsimlar_words = ['talent']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = [\"great\",\"acting\",\"skills\"]\n",
    "sentence2 = [\"fine\",\"drama\",\"talent\"]\n",
    "similarPairs = [[\"great\",\"good\"],[\"fine\",\"good\"],[\"drama\",\"acting\"], [\"skills\",\"talent\"]]\n",
    "is_similar_v2(sentence1, sentence2, similarPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5fd1d-57eb-41c3-be02-a13d1f8c58a0",
   "metadata": {},
   "source": [
    "# Vanta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a842ac9-2e13-4326-adae-7da0de70e93c",
   "metadata": {},
   "source": [
    "### Problem 1: \n",
    "- Given: check_day, employee:{start_day}, return pending pending, complete, overdue + days_overdue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71217c-ecb9-4a38-8702-a6d96a84a1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "468cb6a0-5fb4-4071-849d-370a72d43659",
   "metadata": {},
   "source": [
    "### Problem 2: Given a employee [ {group: 'a', parent_group=[], child_group=['c']]\n",
    "    * aggregate and return {group_id: { } }\n",
    "    * This problem has the transitive nature to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28954680-6a04-4a4a-8d63-3f4c28170334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['b', 'c'], 'b': ['c'], 'c': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees = [ \n",
    "    {'group': 'a', 'parent_group': [], 'child_group': ['b'] },\n",
    "    {'group': 'b', 'parent_group': ['a'], 'child_group': ['c'] },\n",
    "    {'group': 'c', 'parent_group': [], 'child_group': [] },\n",
    "]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_transitive_relation(employees):\n",
    "    parent_to_children = defaultdict(list)\n",
    "    for e in employees:\n",
    "        parent_to_children[e['group']] += e['child_group']\n",
    "\n",
    "    def dfs(group, visited):\n",
    "        for c in parent_to_children[group]:\n",
    "            if c not in visited:\n",
    "                visited.add(c)\n",
    "                dfs(c, visited)\n",
    "    \n",
    "    transitive_relationship = {}\n",
    "    for e in employees:\n",
    "        group = e['group']\n",
    "        visited_chidren = set()\n",
    "        dfs(group, visited_chidren)\n",
    "        transitive_relationship[group] = sorted(visited_chidren)\n",
    "        \n",
    "        \n",
    "    return transitive_relationship\n",
    "\n",
    "transitive_relations = find_transitive_relation(employees)\n",
    "transitive_relations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1333c5a-1b32-4193-bbd0-d8b5f4e57910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_upward(transitive_relations, employees):\n",
    "    # Build group_values from employees\n",
    "    group_values = defaultdict(int)\n",
    "    for emp in employees:\n",
    "        group[emp['group']] += 1\n",
    "        \n",
    "    memo = {}\n",
    "\n",
    "    def compute_aggregate(group):\n",
    "        if group in memo:\n",
    "            return memo[group]\n",
    "        total = group_values.get(group, 0)\n",
    "        for child in transitive_relations.get(group, []):\n",
    "            total += compute_aggregate(child)\n",
    "        memo[group] = total\n",
    "        return total\n",
    "\n",
    "    return {group: compute_aggregate(group) for group in transitive_relations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbad961-f69b-4aea-966e-0b3baceab1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd45dc90-818d-430b-8c01-5d76a461e305",
   "metadata": {},
   "source": [
    "- Why does DFS works better than BFS here?\n",
    "DFS is more cleane, efficient, and easier to implement\n",
    "\n",
    "```\n",
    "Feature\t                          DFS ✅\tBFS\n",
    "Traverse all reachable nodes\t  ✔️\t    ✔️\n",
    "Simple to implement\t              ✔️\t    ✖️\n",
    "Memory-efficient for deep trees\t  ✔️\t    ✖️\n",
    "Useful for shortest paths\t      ✖️\t    ✔️\n",
    "Needs level-order traversal\t      ✖️\t    ✔️\n",
    "```\n",
    "1. Goal: reach all descendents\n",
    "You're not looking for the shortest path or minimum number of hops — you're looking to collect all reachable child groups from a given group. DFS is great at this because it naturally explores all paths deeply before backtracking, which is exactly what we need.\n",
    "\n",
    "2. Memory efficiency: BFS requires a queue; DFS requires a stack, which is more space efficient for deep hierarchies like group structure\n",
    "\n",
    "3. No need for level information: BFS is ideal when level by level information matters, ie find all groups within 2 levels, ie shortest chain of commands from A to Z.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cdd013-258a-41e5-8ebb-ede2422f41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFS implementation of above\n",
    "from collections import deque\n",
    "\n",
    "def bfs(start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        for child in graph[node]:\n",
    "            if child not in visited:\n",
    "                visited.add(child)\n",
    "                queue.append(child)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115c56b-046e-4c8e-aad9-07a018b01d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
