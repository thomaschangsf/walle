{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe332b5-b8b8-4ad3-b4b0-2ee7b4fe5175",
   "metadata": {},
   "source": [
    "# 1 Learnings\n",
    "- Walk through ALL the examples fefore designing the alogorithms\n",
    "- Use more descriptive variable, helpful toward end of problem and things get blurred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b9557-4540-40ce-85b1-47879a0533ee",
   "metadata": {},
   "source": [
    "### Algorithm Families\n",
    "- Sub Linear\n",
    "    * Constant\n",
    "    * O(1)\n",
    "- Polynomial\n",
    "    * Linear: O(N)\n",
    "    * O(N Log N)\n",
    "    * O($N^2$)\n",
    "- Exponential\n",
    "    * recursive algorithm ==can== be exponential\n",
    "    * O($N^3$)\n",
    "    * Exponential: O($2^n$)\n",
    "        - Recursive algo solves a problem of size N by solving ==two== smaller problem of size N-1. Without maintaing state, we could end up with duplicate work.\n",
    "        - Ex: Tower of Hanoi:\n",
    "    * Factorial: O(N!)\n",
    "        - Generate all permutation of a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d502b6-70c0-49c4-ba23-6c228f72531f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4b22f2b-7fb0-457e-bcab-8ee80056a875",
   "metadata": {},
   "source": [
    "# 2 Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ab47d-fb3b-42ec-b525-4270051f2dbd",
   "metadata": {},
   "source": [
    "### Hangman (MoveWorks)\n",
    "- Write a function to predict the next probable word, give:\n",
    "    * mystery_word: d _ _ \n",
    "    * previous_guesses: ['d']\n",
    "    * word_pool: [\"dry\", \"don\", \"apple\", \"dog\", \"dri\"]\n",
    "- Output: o because o is alpha numerically smaller than r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3f31e72-4f34-4c6f-9331-efcb8607d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Edge cases missed: mystery_word has to be same len as word_pool\n",
    "def predict_next_char(mystery_word, prev_guesses, word_pool):\n",
    "    # --------------------------------------\n",
    "    # Build stats\n",
    "    # --------------------------------------\n",
    "    probability_map = Counter()\n",
    "    for w in word_pool:\n",
    "        #probability_map.update(list(w)) # w.split(\" \") does not work\n",
    "        probability_map.update([c for c in w])\n",
    "        \n",
    "    # --------------------------------------\n",
    "    # Filter: Create word_candidates\n",
    "    # --------------------------------------\n",
    "    index_to_alphabets = [ (i, c) for i, c in enumerate(mystery_word) if c.isalpha() ]\n",
    "    word_candidates = []\n",
    "    for w in word_pool:\n",
    "        if len(w) != len(mystery_word):\n",
    "            continue\n",
    "        if all(w[i] == c for i, c in index_to_alphabets):\n",
    "            word_candidates.append(w)\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Rank\n",
    "    # --------------------------------------\n",
    "    demand_prediction = []\n",
    "    for i in range(len(mystery_word)):\n",
    "        if mystery_word[i].isalpha():\n",
    "            continue\n",
    "        for w in word_candidates:\n",
    "            demand_prediction.append( (probability_map[w[i]], w[i]) )\n",
    "    \n",
    "    demand_prediction.sort(key=lambda t: (-t[0], t[1]) )\n",
    "    \n",
    "    return score_prediction[0][1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f4cd76-6d6e-4105-9ae3-6ede73b2ce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 4, 'p': 2, 'n': 2, 'l': 1, 'e': 1, 'b': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "w1 = \"apple\"\n",
    "w2 = \"banana\"\n",
    "c = Counter([c for c in w1])\n",
    "\n",
    "c.update([c for c in w2])\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05dc9f-b643-472a-97a3-dd32700a9e29",
   "metadata": {},
   "source": [
    "### Average of window_size [Facebook]\n",
    "- Given an array arr, return an result where the value is the average of the preceding window size\n",
    "- Example:\n",
    "    * Inputs: window_size =3, arr=[1, 2, 3, 4, 5]\n",
    "    * Output: result = [6/3=2, 9/3=3, 12/3=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c97af5-6656-484f-95e0-1edb92650f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3.0, 4.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learning: prefix_sum[i[ is the sum \"INCLUDEING\" arr[i]\n",
    "def find_avg_of_window(arr= [1, 2, 3, 4, 5], window_size=3):\n",
    "    if len(arr) < window_size:\n",
    "        return []\n",
    "    \n",
    "    prefix_sums = [arr[0]]\n",
    "    # prefix_sum = [1, 3, 6, 10, 15]\n",
    "    for i in range(1, len(arr)):\n",
    "        prefix_sums.append(prefix_sums[i-1] + arr[i])\n",
    "\n",
    "    result = [prefix_sums[window_size-1]]\n",
    "    for j in range(window_size, len(arr)):\n",
    "        result.append( (prefix_sums[j] - prefix_sums[j-window_size])/window_size )\n",
    "    \n",
    "    return result\n",
    "\n",
    "find_avg_of_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f480c48b-df78-4266-928f-8ab62ef1db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LCA\n",
    "#       3\n",
    "#      /  \\\n",
    "#     9    7\n",
    "#   / \\     \\\n",
    "#  2   6     4\n",
    "#\n",
    "# TC1: 2, 6 --> 9\n",
    "# TC2: 7, 6 --> 3\n",
    "# TC3: 7, 4 --> 7\n",
    "\n",
    "def lca(root, left_node, right_node):\n",
    "    # dfs returns null or a node in (lca, left_node, right_node) \n",
    "    def dfs(curr_node):\n",
    "        # Base condition\n",
    "        if not curr_node or (curr_node == left_node) or (curr_node == right_node):\n",
    "            return curr_node\n",
    "\n",
    "        left = dfs( curr_node.left )\n",
    "        right = dfs( curr_node.right )\n",
    "        if left and right:\n",
    "            return curr_node\n",
    "        else:\n",
    "            return left or right\n",
    "    \n",
    "    return dfs(root)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328b607-ee3f-401d-94e7-605751957ad1",
   "metadata": {},
   "source": [
    "### Raspbery AI\n",
    "- Given a corpus of sentences and char_count, return  sentence(s) following a specific heuristc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16bf9cb5-f322-42fd-a120-46da894c81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def recommend(sentences, char_cnt):\n",
    "    # Step 1: Estimate the unigram distribution from the input documents\n",
    "    word_counts = Counter()\n",
    "    for s in sentences:\n",
    "        word_counts.update(s.split(\" \"))\n",
    "    N = sum(word_counts.values())\n",
    "    p = { w: cnt/N for w, cnt in word_counts.items() }\n",
    "\n",
    "    # runtime: n(log n) if requires sort (ie largeer n) or O(n) for small  \n",
    "    best_word = word_counts.most_common(1)[0][0] # most_common return a list of tuples (word, cnt) in descemdomg prder\n",
    "\n",
    "    summary = \"\"\n",
    "    while char_cnt > 0:\n",
    "        # Step 2: For each sentence s_j, assign a weight equal to the average probability of the words it contain\n",
    "        avgscore_to_sentence = []\n",
    "        for s in sentences:\n",
    "            scores = [ p[word] for word in s.split(\" \") if word in p ]\n",
    "            avgscore_to_sentence.append( ( sum(scores) / len(scores), s) )\n",
    "\n",
    "        # Step 3: Pick the highest scoring sentence that also contains the best scoring word and add it to the summary (so long as it fits within the length limit)\n",
    "        avgscore_to_sentence_filtered = [ (score, s) for score, s in avgscore_to_sentence if best_word in s]\n",
    "        avgscore_to_sentence_filtered.sort(key=lambda t: t[0])\n",
    "        best_sentence = avgscore_to_sentence_filtered[-1][1]\n",
    "\n",
    "        # Step 4: For each word in teh sentence selected in step 3, update its probability\n",
    "        for w in best_sentence.split(\" \"):\n",
    "            p[word] = p[word] * p[word]\n",
    "\n",
    "        # Step 5: If the desired summary length has not been reached, go to step 2\n",
    "        if char_cnt < len(best_sentence):\n",
    "            return summary\n",
    "        else:\n",
    "            char_cnt -= len(best_sentence)\n",
    "            summary += best_sentence\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb5a3f32-06ac-4146-b1a0-7d2b56a01073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"apple\" in \"apple pie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3c6dd-682c-44ad-a41c-92e0f530e915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
